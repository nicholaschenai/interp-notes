### Dynamical and Bayesian Phase Transitions in a Toy Model of Superposition 
[[Paper](https://arxiv.org/abs/2310.06301)]
- Also see explainer [[Growth and Form in a Toy Model of Superposition](https://www.lesswrong.com/posts/jvGqQGDrYzZM4MyaN/growth-and-form-in-a-toy-model-of-superposition)]

### Investigating the learning coefficient of modular addition: hackathon project
[[Post](https://www.lesswrong.com/posts/4v3hMuKfsGatLXPgt/investigating-the-learning-coefficient-of-modular-addition)]

### Understanding Addition in Transformers
[[Paper](https://arxiv.org/abs/2310.13121)]
- Observation: Phase transition for each digit in integer addition
- This paper: Model trains each digit semi-independently, hence multiple phase transitions

### Multi-Component Learning and S-Curves
[[Post](https://www.alignmentforum.org/posts/RKDQCB6smLWgs2Mhr/multi-component-learning-and-s-curves)]
-  for low rank matrix, when we increase rank, more chances ...(some probability argument) ... dissipates grokking (immediate learning)